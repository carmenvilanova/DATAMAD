{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto DATAMAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Carga de datos de Idealista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar importamos las librerías:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "## Esta librería no te servirá en este análisis, pero\n",
    "## es la librería básica para scrapear páginas más sencillas\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "## Esta sí. Con ella, sacaremos datos del HTML.\n",
    "\n",
    "import random\n",
    "\n",
    "## Para usar números aleatorios. Esta no era tan complicada.\n",
    "## La usaremos para no usar el mismo tiempo siempre al scrapear.\n",
    "\n",
    "import time\n",
    "\n",
    "## Con esta metemos el retardo a la máquina. Las máquinas van rápidas. Yo no.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## EL bread and butter del Data Science. Tablas y operaciones aritméticas.\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "## Esta es la manera para usar selenium normal, pero nosotros tenemos que parecer humanos.\n",
    "## Por eso, usamos la siguiente librería.\n",
    "\n",
    "import undetected_chromedriver as uc\n",
    "\n",
    "## La persona que desarrolló esto es un crack. Configuró todos los proxies y\n",
    "## demás (digo demás porque no se qué brujería ha usado) para ser indetectable.\n",
    "## Usaremos este browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciamos el explorador, en este caso utilizamos Chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = uc.Chrome()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección extraemos de la página de idealista deseada los ids de las viviendas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.idealista.com/venta-viviendas/madrid-madrid/pagina-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.htm\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      8\u001b[0m browser\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[1;32m---> 10\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     browser\u001b[38;5;241m.\u001b[39mfind_element(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxpath\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m//*[@id=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdidomi-notice-agree-button\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mclick()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x=1\n",
    "ids = []\n",
    "\n",
    "while True:\n",
    "    \n",
    "    url = f'https://www.idealista.com/venta-viviendas/madrid-madrid/pagina-{x}.htm'\n",
    "    \n",
    "    browser.get(url)\n",
    "    \n",
    "    time.sleep(random.randint(10,12))\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        browser.find_element(\"xpath\",'//*[@id=\"didomi-notice-agree-button\"]').click()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    html = browser.page_source\n",
    "    \n",
    "    soup = bs(html, 'lxml')\n",
    "    \n",
    "    pagina_actual = int(soup.find('main',{'class':'listing-items'}).find('div',{'class':'pagination'}).find('li',{'class':'selected'}).text)\n",
    "    \n",
    "    if x == pagina_actual:\n",
    "\n",
    "        articles = soup.find('main',{'class':'listing-items'}).find_all('article')\n",
    "\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "    x = x+1\n",
    "    \n",
    "    for article in articles:\n",
    "        \n",
    "        id_muebles = article.get('data-element-id')\n",
    "        \n",
    "        ids.append(id_muebles)\n",
    "        \n",
    "        time.sleep(random.randint(1,3))\n",
    "        print(id_muebles)\n",
    "    \n",
    "    ids = [muebles for muebles in ids if muebles is not None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos un data frame con los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_casas = pd.DataFrame(ids)\n",
    "ids_casas.columns = ['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y lo exportamos a un csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_casas.to_csv('ids_casas.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casas = pd.Series()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, a partir del id de las casas, extraemos el resto de datos utilizando BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsear_inmueble(id_inmueble):\n",
    "    \n",
    "    print( '\\n Casa numero: ' + id_inmueble)\n",
    "    \n",
    "    url = \"https://www.idealista.com/inmueble/\" + id_inmueble + \"/\"\n",
    "    \n",
    "    browser.get(url)\n",
    "\n",
    "    html = browser.page_source\n",
    "    \n",
    "    soup = bs(html, 'lxml')\n",
    "\n",
    "    titulo = soup.find('span',{'class':'main-info__title-main'}).text\n",
    "    \n",
    "    print('\\n Titulo: ' + titulo)\n",
    "    \n",
    "    localizacion = soup.find('span',{'class':'main-info__title-minor'}).text.split(',')[0]\n",
    "\n",
    "    print('\\n Localizacion: ' + localizacion)\n",
    "    precio = int(soup.find('span',{'class':'txt-bold'}).text.replace('.',''))\n",
    "\n",
    "    c1 = soup.find('div',{'class':'details-property'}).find('div',{'class': 'details-property-feature-one'})\n",
    "\n",
    "    caract_basicas = [caract.text.strip() for caract in c1.find_all('li')]\n",
    "    \n",
    "    #print('Caracteristicas basicas:' + caract_basicas)\n",
    "\n",
    "    c2 = soup.find('div',{'class':'details-property'}).find('div',{'class': 'details-property-feature-two'})\n",
    "\n",
    "    caract_extra = [caract.text.strip() for caract in c2.find_all('li')]\n",
    "    \n",
    "    #print('Caracteristicas extras:' + caract_extra)\n",
    "    \n",
    "    casas['titulo'] = titulo\n",
    "    \n",
    "    casas['localizacion'] = localizacion\n",
    "    \n",
    "    casas['precio'] = precio\n",
    "    \n",
    "    casas['caracteristicas_basicas'] = caract_basicas\n",
    "    \n",
    "    casas['caracteristicas_extras'] = caract_extra\n",
    "    \n",
    "    df_casas = pd.DataFrame(casas)\n",
    "    \n",
    "    return(df_casas.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_casas = parsear_inmueble(ids_casas.iloc[0].id)\n",
    "\n",
    "for i in range(1,len(ids)):\n",
    "    \n",
    "    df_casas = pd.concat([df_casas,parsear_inmueble(ids[i])])\n",
    "    \n",
    "    time.sleep(random.randint(4,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_casas.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y exportamos todos los datos a otro csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_casas.to_csv('casas_idealista.csv', index = False, sep = ';', encoding = 'utf-16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Carga de datos DATAMAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datos de centros sanitarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carme\\AppData\\Local\\Temp\\ipykernel_11968\\87057601.py:41: FutureWarning: This function is deprecated. See: https://pyproj4.github.io/pyproj/stable/gotchas.html#upgrading-to-pyproj-2-from-pyproj-1\n",
      "  lon, lat = transform(utm_proj, wgs84_proj, utm_x, utm_y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo 'datos_madrid_latlon.csv' generado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "# Importamos las librerías necesarias\n",
    "import csv\n",
    "import requests\n",
    "from pyproj import Proj, transform\n",
    "\n",
    "# URL del archivo CSV\n",
    "base_url = \"https://datos.comunidad.madrid/catalogo/dataset/d8a0a444-adf5-4c04-8999-0eac3de52cb7/resource/2948b4da-8b39-42b7-b667-779a5284f39d/download/centros_servicios_establecimientos_sanitarios.csv\"\n",
    "\n",
    "# Realizamos la petición\n",
    "result = requests.get(base_url)\n",
    "\n",
    "# Si la conexión es exitosa, procesamos el CSV\n",
    "if result.status_code == 200:\n",
    "    # Convertimos el texto del CSV en una lista de diccionarios, con ';' como delimitador\n",
    "    csv_data = result.text.splitlines()\n",
    "    reader = csv.DictReader(csv_data, delimiter=';')\n",
    "\n",
    "    # Filtramos solo los datos del municipio de Madrid y eliminamos duplicados por 'centro_nro_registro'\n",
    "    seen_centers = set()\n",
    "    filtered_data = []\n",
    "    for row in reader:\n",
    "        centro_nro_registro = row.get(\"centro_nro_registro\")\n",
    "        if row.get(\"municipio_nombre\") and row[\"municipio_nombre\"].lower() == \"madrid\" and centro_nro_registro not in seen_centers:\n",
    "            seen_centers.add(centro_nro_registro)  # Agregamos el centro para evitar duplicados\n",
    "            filtered_data.append(row)\n",
    "\n",
    "    # Configuramos el sistema de coordenadas UTM y WGS84 (latitud/longitud)\n",
    "    utm_proj = Proj(proj='utm', zone=30, ellps='WGS84')  # UTM Zone 30T (España)\n",
    "    wgs84_proj = Proj(proj='latlong', datum='WGS84')\n",
    "\n",
    "    # Convertimos las coordenadas UTM a latitud y longitud\n",
    "    for row in filtered_data:\n",
    "        try:\n",
    "            # Verificamos si las coordenadas UTM están presentes y no están vacías\n",
    "            if row[\"localizacion_coordenada_x\"] and row[\"localizacion_coordenada_y\"]:\n",
    "                # Convertimos las coordenadas UTM a float\n",
    "                utm_x = float(row[\"localizacion_coordenada_x\"])\n",
    "                utm_y = float(row[\"localizacion_coordenada_y\"])\n",
    "                \n",
    "                # Convertimos a latitud y longitud\n",
    "                lon, lat = transform(utm_proj, wgs84_proj, utm_x, utm_y)\n",
    "                \n",
    "                # Añadimos las nuevas coordenadas al diccionario\n",
    "                row[\"latitud\"] = lat\n",
    "                row[\"longitud\"] = lon\n",
    "            else:\n",
    "                # Si las coordenadas están vacías, asignamos None o dejamos en blanco\n",
    "                row[\"latitud\"] = None\n",
    "                row[\"longitud\"] = None\n",
    "\n",
    "            # Eliminamos la columna 'oferta_asistencial' si existe\n",
    "            row.pop(\"oferta_asistencial\", None)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error al convertir coordenadas para la fila: {row['centro_nro_registro']}\", e)\n",
    "\n",
    "    # Guardamos los datos filtrados y transformados en un nuevo archivo CSV\n",
    "    with open(\"datos_madrid_latlon.csv\", mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        # Revisamos si 'latitud' y 'longitud' ya están en las claves y los agregamos solo si no están\n",
    "        fieldnames = list(filtered_data[0].keys())\n",
    "        if \"latitud\" not in fieldnames:\n",
    "            fieldnames.append(\"latitud\")\n",
    "        if \"longitud\" not in fieldnames:\n",
    "            fieldnames.append(\"longitud\")\n",
    "\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(filtered_data)\n",
    "    \n",
    "    print(\"Archivo 'datos_madrid_latlon.csv' generado exitosamente.\")\n",
    "else:\n",
    "    print(\"Error en la solicitud:\", result.status_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Limpieza de datos y coordenadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora procedemos al tratamiento de los datos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              titulo localizacion   precio  \\\n",
      "0          Piso en venta en calle del Duque de Sesto         Goya  1290000   \n",
      "1          Piso en venta en calle del Duque de Sesto         Goya  1290000   \n",
      "2                          Ático en venta en Adelfas       Retiro   880000   \n",
      "3   Chalet pareado en venta en calle Virgen de lo...      Aravaca  2280000   \n",
      "4   Casa o chalet independiente en venta en calle...   Valdemarín  3500000   \n",
      "\n",
      "                             caracteristicas_basicas  \\\n",
      "0  [133 m² construidos, 2 habitaciones, 3 baños, ...   \n",
      "1  [133 m² construidos, 2 habitaciones, 3 baños, ...   \n",
      "2  [175 m² construidos, 4 habitaciones, 3 baños, ...   \n",
      "3  [Chalet pareado, 505 m² construidos, 7 habitac...   \n",
      "4  [Casa o chalet independiente, 749 m² construid...   \n",
      "\n",
      "                              caracteristicas_extras  numero_calle  \\\n",
      "0   ['Aire acondicionado', 'Consumo:', 'Emisiones:']           NaN   \n",
      "1   ['Aire acondicionado', 'Consumo:', 'Emisiones:']           NaN   \n",
      "2  ['Aire acondicionado', 'Piscina', 'Zonas verde...           NaN   \n",
      "3  ['Aire acondicionado', 'Piscina', 'Jardín', 'E...           NaN   \n",
      "4  ['Aire acondicionado', 'Piscina', 'Jardín', 'E...           NaN   \n",
      "\n",
      "   metros_cuadrados  habitaciones  baños  parcela_m2 plaza_garaje  \\\n",
      "0               133           2.0    3.0         NaN         None   \n",
      "1               133           2.0    3.0         NaN         None   \n",
      "2               175           4.0    3.0         NaN         True   \n",
      "3               505           7.0    5.0      1127.0         True   \n",
      "4               749           7.0   10.0      2987.0         True   \n",
      "\n",
      "                     estado orientacion  año_construccion  calefaccion  \\\n",
      "0  Segunda mano/buen estado         sur            1941.0          Gas   \n",
      "1  Segunda mano/buen estado         sur            1941.0          Gas   \n",
      "2  Segunda mano/buen estado        None               NaN  Gas natural   \n",
      "3  Segunda mano/buen estado        None            1997.0         None   \n",
      "4  Segunda mano/buen estado        None            2003.0         None   \n",
      "\n",
      "               planta ascensor  \n",
      "0  Planta 1ª exterior     True  \n",
      "1  Planta 1ª exterior     True  \n",
      "2  Planta 6ª exterior     True  \n",
      "3                None     None  \n",
      "4                None     None  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "df = pd.read_csv(\"casas_idealista.csv\", sep=\";\", encoding=\"utf-16\")\n",
    "\n",
    "# Convertir 'caracteristicas_basicas' en una lista de Python, si no está ya en ese formato\n",
    "df['caracteristicas_basicas'] = df['caracteristicas_basicas'].apply(eval)\n",
    "\n",
    "# Función para extraer el número de calle\n",
    "def extraer_numero_calle(titulo):\n",
    "    # Busca un número en la dirección que esté seguido de coma o espacio\n",
    "    match = re.search(r',\\s?(\\d+)', titulo)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "# Aplicar la función para crear la columna 'numero_calle'\n",
    "df['numero_calle'] = df['titulo'].apply(extraer_numero_calle)\n",
    "\n",
    "# Función para extraer los datos de 'caracteristicas_basicas'\n",
    "def extraer_datos(lista):\n",
    "    datos = {\n",
    "        'metros_cuadrados': None,\n",
    "        'habitaciones': None,\n",
    "        'baños': None,\n",
    "        'parcela_m2': None,\n",
    "        'plaza_garaje': None,\n",
    "        'estado': None,\n",
    "        'orientacion': None,\n",
    "        'año_construccion': None,\n",
    "        'calefaccion': None,\n",
    "        'planta': None,\n",
    "        'ascensor': None,\n",
    "    }\n",
    "\n",
    "    for item in lista:\n",
    "        # Solo procesa elementos que contengan características específicas de la vivienda\n",
    "        if re.search(r'\\bm²\\b|\\bhabitaciones\\b|\\bbaños\\b|garaje|estado|Orientación|Construido en|Calefacción|Planta|ascensor|Parcela', item):\n",
    "            if re.search(r'\\d+\\s?m² construidos', item):\n",
    "                datos['metros_cuadrados'] = int(re.search(r'\\d+', item).group())\n",
    "            elif 'habitaciones' in item:\n",
    "                datos['habitaciones'] = int(re.search(r'\\d+', item).group())\n",
    "            elif 'baños' in item:\n",
    "                datos['baños'] = int(re.search(r'\\d+', item).group())\n",
    "            elif 'Parcela de' in item:\n",
    "                datos['parcela_m2'] = int(re.search(r'\\d+', item.replace('.', '')).group())\n",
    "            elif 'garaje' in item:\n",
    "                datos['plaza_garaje'] = True\n",
    "            elif 'Segunda mano' in item or 'para reformar' in item:\n",
    "                datos['estado'] = item\n",
    "            elif 'Orientación' in item:\n",
    "                datos['orientacion'] = item.split(' ')[-1]\n",
    "            elif 'Construido en' in item:\n",
    "                datos['año_construccion'] = int(re.search(r'\\d+', item).group())\n",
    "            elif 'Calefacción' in item:\n",
    "                datos['calefaccion'] = item.split(': ')[-1]\n",
    "            elif 'Planta' in item:\n",
    "                datos['planta'] = item\n",
    "            elif 'ascensor' in item:\n",
    "                datos['ascensor'] = True\n",
    "\n",
    "    return datos\n",
    "\n",
    "# Aplicar la función y expandir los resultados en el DataFrame\n",
    "datos_df = df['caracteristicas_basicas'].apply(extraer_datos).apply(pd.Series)\n",
    "\n",
    "# Combinar los datos originales con las nuevas columnas\n",
    "df = pd.concat([df, datos_df], axis=1)\n",
    "\n",
    "# Guardar el DataFrame en un nuevo archivo CSV si se desea\n",
    "df.to_csv('casas_completo.csv', index=False, sep=';')\n",
    "# Guardar el DataFrame en un nuevo archivo CSV con punto y coma como delimitador\n",
    "\n",
    "\n",
    "\n",
    "# Mostrar el DataFrame final\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadimos las coordenadas a las direcciones utilizando DireccionesVigentes.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo 'casas_completo_actualizado.csv' creado con éxito.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Cargar los datos\n",
    "direcciones_df = pd.read_csv(\"DireccionesVigentes.csv\", encoding=\"latin1\", delimiter=\";\")\n",
    "casas_df = pd.read_csv(\"casas_completo.csv\", encoding=\"utf-8\", delimiter=\";\")\n",
    "\n",
    "# Limpiar y normalizar nombres de calles en DireccionesVigentes\n",
    "direcciones_df[\"VIA_NOMBRE\"] = direcciones_df[\"VIA_NOMBRE\"].str.upper().str.strip()\n",
    "\n",
    "# Eliminar duplicados en direcciones_df para que solo haya un valor de coordenadas por calle\n",
    "direcciones_df = direcciones_df.drop_duplicates(subset=[\"VIA_NOMBRE\"], keep=\"first\")\n",
    "\n",
    "# Función para extraer y normalizar el nombre de la calle del título\n",
    "def extraer_nombre_calle(titulo):\n",
    "    # Buscar el tipo de vía seguido de la última palabra del nombre de la calle\n",
    "    match = re.search(r'\\b(CALLE|AVENIDA|PASEO|PLAZA|RONDA|CAMINO)\\s+(?:DE(L|LA)?\\s+)?(\\w+)$', titulo, re.IGNORECASE)\n",
    "    if match:\n",
    "        return match.group(3).upper().strip()  # Solo capturar la última palabra\n",
    "    return None\n",
    "\n",
    "# Crear una columna temporal en casas_df para almacenar el nombre de la calle extraído\n",
    "casas_df[\"CALLE_EXTRAIDA\"] = casas_df[\"titulo\"].apply(extraer_nombre_calle)\n",
    "\n",
    "# Hacer el merge de ambas bases de datos en función del nombre de la calle\n",
    "casas_completo = casas_df.merge(direcciones_df[['VIA_NOMBRE', 'LATITUD', 'LONGITUD']],\n",
    "                                left_on=\"CALLE_EXTRAIDA\", right_on=\"VIA_NOMBRE\", how=\"left\")\n",
    "\n",
    "# Eliminar la columna temporal y renombrar columnas\n",
    "casas_completo.drop(columns=[\"CALLE_EXTRAIDA\", \"VIA_NOMBRE\"], inplace=True)\n",
    "\n",
    "# Guardar el archivo actualizado\n",
    "casas_completo.to_csv(\"casas_completo_actualizado.csv\", index=False)\n",
    "print(\"Archivo 'casas_completo_actualizado.csv' creado con éxito.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí eliminamos todos aquellos pisos de los cuales no ha sido posible obtener las coordenadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo 'casas_con_coordenadas.csv' creado con éxito.\n"
     ]
    }
   ],
   "source": [
    "casas_con_coordenadas = casas_completo.dropna(subset=['LATITUD', 'LONGITUD'])\n",
    "\n",
    "# Guardar el archivo de casas con coordenadas\n",
    "casas_con_coordenadas.to_csv(\"casas_con_coordenadas.csv\", index=False)\n",
    "print(\"Archivo 'casas_con_coordenadas.csv' creado con éxito.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas disponibles en el DataFrame: ['titulo', 'localizacion', 'precio', 'numero_calle', 'metros_cuadrados', 'habitaciones', 'baños', 'parcela_m2', 'plaza_garaje', 'estado', 'orientacion', 'año_construccion', 'calefaccion', 'planta', 'ascensor', 'LATITUD', 'LONGITUD']\n",
      "Archivo 'casas_con_coordenadas_transformadas.csv' creado con éxito.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Definir una función para convertir coordenadas de DMS a decimal\n",
    "def dms_a_decimal(dms):\n",
    "    # Separar grados, minutos, segundos y dirección\n",
    "    degrees, minutes, seconds, direction = re.split(\"[°'\\\" ]+\", dms.strip())\n",
    "    decimal = float(degrees) + float(minutes) / 60 + float(seconds) / 3600\n",
    "    if direction in ['S', 'W']:\n",
    "        decimal = -decimal\n",
    "    return decimal\n",
    "\n",
    "# Cargar los datos desde un CSV\n",
    "casas_df = pd.read_csv(\"casas_con_coordenadas.csv\", encoding=\"utf-8\", delimiter=\",\")\n",
    "\n",
    "# Imprimir los nombres de las columnas para depuración\n",
    "print(\"Columnas disponibles en el DataFrame:\", casas_df.columns.tolist())\n",
    "\n",
    "# Convertir las coordenadas de LATITUD y LONGITUD a decimal\n",
    "# Asegúrate de que los nombres coincidan exactamente con los nombres de columna\n",
    "if 'LATITUD' in casas_df.columns and 'LONGITUD' in casas_df.columns:\n",
    "    casas_df['LATITUD'] = casas_df['LATITUD'].apply(dms_a_decimal)\n",
    "    casas_df['LONGITUD'] = casas_df['LONGITUD'].apply(dms_a_decimal)\n",
    "else:\n",
    "    print(\"No se encontraron las columnas 'LATITUD' y/o 'LONGITUD' en el DataFrame.\")\n",
    "\n",
    "# Guardar el nuevo archivo CSV con las coordenadas transformadas\n",
    "casas_df.to_csv(\"casas_con_coordenadas_transformadas.csv\", index=False, sep=';')\n",
    "print(\"Archivo 'casas_con_coordenadas_transformadas.csv' creado con éxito.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Aplicacion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
